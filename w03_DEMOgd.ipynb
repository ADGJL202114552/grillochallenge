{"cells":[{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"TGHFNCPqTi4A"},"source":["\n","\n","# Gradient Descent\n","## Note\n","This is copied from  https://d2l.ai/chapter_optimization/gd.html\n","\n","\n","In this section we are going to introduce the basic concepts underlying *gradient descent*.\n","Although it is rarely used directly in deep learning, an understanding of gradient descent is key to understanding stochastic gradient descent algorithms. \n","For instance, the optimization problem might diverge due to an overly large learning rate. This phenomenon can already be seen in gradient descent. Likewise, preconditioning is a common technique in gradient descent and carries over to more advanced algorithms.\n","Let us start with a simple special case.\n","\n","\n","## One-Dimensional Gradient Descent\n","\n","Gradient descent in one dimension is an excellent example to explain why the gradient descent algorithm may reduce the value of the objective function. Consider some continuously differentiable real-valued function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$. Using a Taylor expansion we obtain\n","\n","$$f(x + \\epsilon) = f(x) + \\epsilon f'(x) + \\mathcal{O}(\\epsilon^2).$$\n",":eqlabel:`gd-taylor`\n","\n","That is, in first-order approximation $f(x+\\epsilon)$ is given by the function value $f(x)$ and the first derivative $f'(x)$ at $x$. It is not unreasonable to assume that for small $\\epsilon$ moving in the direction of the negative gradient will decrease $f$. To keep things simple we pick a fixed step size $\\eta > 0$ and choose $\\epsilon = -\\eta f'(x)$. Plugging this into the Taylor expansion above we get\n","\n","$$f(x - \\eta f'(x)) = f(x) - \\eta f'^2(x) + \\mathcal{O}(\\eta^2 f'^2(x)).$$\n",":eqlabel:`gd-taylor-2`\n","\n","If the derivative $f'(x) \\neq 0$ does not vanish we make progress since $\\eta f'^2(x)>0$. Moreover, we can always choose $\\eta$ small enough for the higher-order terms to become irrelevant. Hence we arrive at\n","\n","$$f(x - \\eta f'(x)) \\lessapprox f(x).$$\n","\n","This means that, if we use\n","\n","$$x \\leftarrow x - \\eta f'(x)$$\n","\n","to iterate $x$, the value of function $f(x)$ might decline. Therefore, in gradient descent we first choose an initial value $x$ and a constant $\\eta > 0$ and then use them to continuously iterate $x$ until the stop condition is reached, for example, when the magnitude of the gradient $|f'(x)|$ is small enough or the number of iterations has reached a certain value.\n","\n","For simplicity we choose the objective function $f(x)=x^2$ to illustrate how to implement gradient descent. Although we know that $x=0$ is the solution to minimize $f(x)$, we still use this simple function to observe how $x$ changes.\n"]},{"cell_type":"markdown","source":["---\n","\n","## Note for ST456\n","\n","The following command is necessary for downloading some helper functions in TensorFlow used by the [reference book](https://d2l.ai/).\n","\n","If you get a message saying **you need to restart the runtime**, please **do so** before running the rest of the code."],"metadata":{"id":"8QRwLYIYce3y"}},{"cell_type":"code","source":["!mkdir /content/d2l\n","! wget https://raw.githubusercontent.com/d2l-ai/d2l-en/master/d2l/tensorflow.py\n","!mv tensorflow.py /content/d2l\n","\n","#!pip install d2l==0.17.1 2>/dev/null"],"metadata":{"id":"nOUMg5v3c2-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":3,"tab":["tensorflow"],"id":"Nq1hrnC1Ti4D"},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","import tensorflow as tf\n","from d2l import tensorflow as d2l"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":4,"tab":["tensorflow"],"id":"799Rk_tkTi4E"},"outputs":[],"source":["def f(x):  # Objective function\n","    return x ** 2\n","\n","def f_grad(x):  # Gradient (derivative) of the objective function\n","    return 2 * x"]},{"cell_type":"markdown","metadata":{"origin_pos":5,"id":"2e_Q9KUhTi4E"},"source":["Next, we use $x=10$ as the initial value and assume $\\eta=0.2$. Using gradient descent to iterate $x$ for 10 times we can see that, eventually, the value of $x$ approaches the optimal solution.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":6,"tab":["tensorflow"],"id":"iHx07mwXTi4F"},"outputs":[],"source":["def gd(eta, f_grad):\n","    x = 10.0\n","    results = [x]\n","    for i in range(10):\n","        x -= eta * f_grad(x)\n","        results.append(float(x))\n","        print(f'Epoch {i}, x: {x:f}')\n","\n","    #print(f'epoch 10, x: {x:f}')\n","    return results\n","\n","results = gd(0.2, f_grad)"]},{"cell_type":"markdown","metadata":{"origin_pos":7,"id":"fsJ2ZvKdTi4G"},"source":["The progress of optimizing over $x$ can be plotted as follows.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":8,"tab":["tensorflow"],"id":"cR1mifLDTi4G"},"outputs":[],"source":["def show_trace(results, f):\n","    n = max(abs(min(results)), abs(max(results)))\n","    f_line = tf.range(-n, n, 0.01)\n","    d2l.set_figsize()\n","    d2l.plot([f_line, results], [[f(x) for x in f_line], [\n","        f(x) for x in results]], 'x', 'f(x)', fmts=['-', '-o'])\n","\n","show_trace(results, f)"]},{"cell_type":"markdown","metadata":{"origin_pos":9,"id":"21A_VMKZTi4H"},"source":["### Learning Rate\n",":label:`subsec_gd-learningrate`\n","\n","The learning rate $\\eta$ can be set by the algorithm designer. If we use a learning rate that is too small, it will cause $x$ to update very slowly, requiring more iterations to get a better solution. To show what happens in such a case, consider the progress in the same optimization problem for $\\eta = 0.05$. As we can see, even after 10 steps we are still very far from the optimal solution.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":10,"tab":["tensorflow"],"id":"C2EldiL-Ti4H"},"outputs":[],"source":["show_trace(gd(0.05, f_grad), f)"]},{"cell_type":"markdown","metadata":{"origin_pos":11,"id":"39zs5s3YTi4H"},"source":["Conversely, if we use an excessively high learning rate, $\\left|\\eta f'(x)\\right|$ might be too large for the first-order Taylor expansion formula. That is, the term $\\mathcal{O}(\\eta^2 f'^2(x))$ in :eqref:`gd-taylor-2` might become significant. In this case, we cannot guarantee that the iteration of $x$ will be able to lower the value of $f(x)$. For example, when we set the learning rate to $\\eta=1.1$, $x$ overshoots the optimal solution $x=0$ and gradually diverges.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":12,"tab":["tensorflow"],"id":"MTGag1izTi4I"},"outputs":[],"source":["show_trace(gd(1.1, f_grad), f)"]},{"cell_type":"markdown","metadata":{"origin_pos":13,"id":"TP78XxyATi4I"},"source":["### Local Minima\n","\n","To illustrate what happens for nonconvex functions consider the case of $f(x) = x \\cdot \\cos(cx)$ for some constant $c$. This function has infinitely many local minima. Depending on our choice of the learning rate and depending on how well conditioned the problem is, we may end up with one of many solutions. The example below illustrates how an (unrealistically) high learning rate will lead to a poor local minimum.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":14,"tab":["tensorflow"],"id":"uX44evjZTi4I"},"outputs":[],"source":["c = tf.constant(0.15 * np.pi)\n","\n","def f(x):  # Objective function\n","    return x * tf.cos(c * x)\n","\n","def f_grad(x):  # Gradient of the objective function\n","    return tf.cos(c * x) - c * x * tf.sin(c * x)\n","\n","show_trace(gd(2, f_grad), f)"]},{"cell_type":"markdown","metadata":{"origin_pos":15,"id":"dAHEYvXkTi4I"},"source":["## Multivariate Gradient Descent\n","\n","Now that we have a better intuition of the univariate case, let us consider the situation where $\\mathbf{x} = [x_1, x_2, \\ldots, x_d]^\\top$. That is, the objective function $f: \\mathbb{R}^d \\to \\mathbb{R}$ maps vectors into scalars. Correspondingly its gradient is multivariate, too. It is a vector consisting of $d$ partial derivatives:\n","\n","$$\\nabla f(\\mathbf{x}) = \\bigg[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}, \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\mathbf{x})}{\\partial x_d}\\bigg]^\\top.$$\n","\n","Each partial derivative element $\\partial f(\\mathbf{x})/\\partial x_i$ in the gradient indicates the rate of change of $f$ at $\\mathbf{x}$ with respect to the input $x_i$. As before in the univariate case we can use the corresponding Taylor approximation for multivariate functions to get some idea of what we should do. In particular, we have that\n","\n","$$f(\\mathbf{x} + \\boldsymbol{\\epsilon}) = f(\\mathbf{x}) + \\mathbf{\\boldsymbol{\\epsilon}}^\\top \\nabla f(\\mathbf{x}) + \\mathcal{O}(\\|\\boldsymbol{\\epsilon}\\|^2).$$\n",":eqlabel:`gd-multi-taylor`\n","\n","In other words, up to second-order terms in $\\boldsymbol{\\epsilon}$ the direction of steepest descent is given by the negative gradient $-\\nabla f(\\mathbf{x})$. Choosing a suitable learning rate $\\eta > 0$ yields the prototypical gradient descent algorithm:\n","\n","$$\\mathbf{x} \\leftarrow \\mathbf{x} - \\eta \\nabla f(\\mathbf{x}).$$\n","\n","To see how the algorithm behaves in practice let us construct an objective function $f(\\mathbf{x})=x_1^2+2x_2^2$ with a two-dimensional vector $\\mathbf{x} = [x_1, x_2]^\\top$ as input and a scalar as output. The gradient is given by $\\nabla f(\\mathbf{x}) = [2x_1, 4x_2]^\\top$. We will observe the trajectory of $\\mathbf{x}$ by gradient descent from the initial position $[-5, -2]$. \n","\n","To begin with, we need two more helper functions. The first uses an update function and applies it 20 times to the initial value. The second helper visualizes the trajectory of $\\mathbf{x}$.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":16,"tab":["tensorflow"],"id":"TlcyrokZTi4J"},"outputs":[],"source":["def train_2d(trainer, steps=20, f_grad=None):  \n","    \"\"\"Optimize a 2D objective function with a customized trainer.\"\"\"\n","    # `s1` and `s2` are internal state variables that will be used later\n","    x1, x2, s1, s2 = -5, -2, 0, 0\n","    results = [(x1, x2)]\n","    for i in range(steps):\n","        if f_grad:\n","            x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad)\n","        else:\n","            x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n","        results.append((x1, x2))\n","        print(f'Epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')\n","    #print(f'Epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')\n","    return results\n","\n","def show_trace_2d(f, results): \n","    \"\"\"Show the trace of 2D variables during optimization.\"\"\"\n","    d2l.set_figsize()\n","    d2l.plt.plot(*zip(*results), '-o', color='#ff7f0e')\n","    x1, x2 = tf.meshgrid(tf.range(-5.5, 1.0, 0.1),\n","                          tf.range(-3.0, 1.0, 0.1))\n","    d2l.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n","    d2l.plt.xlabel('x1')\n","    d2l.plt.ylabel('x2')"]},{"cell_type":"markdown","metadata":{"origin_pos":17,"id":"Oo9WZwW2Ti4J"},"source":["Next, we observe the trajectory of the optimization variable $\\mathbf{x}$ for learning rate $\\eta = 0.1$. We can see that after 20 steps the value of $\\mathbf{x}$ approaches its minimum at $[0, 0]$. Progress is fairly well-behaved albeit rather slow.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":18,"tab":["tensorflow"],"id":"c_0pGeeCTi4J"},"outputs":[],"source":["def f_2d(x1, x2):  # Objective function\n","    return x1 ** 2 + 2 * x2 ** 2\n","\n","def f_2d_grad(x1, x2):  # Gradient of the objective function\n","    return (2 * x1, 4 * x2)\n","\n","def gd_2d(x1, x2, s1, s2, f_grad):\n","    g1, g2 = f_grad(x1, x2)\n","    return (x1 - eta * g1, x2 - eta * g2, 0, 0)\n","\n","eta = 0.1\n","show_trace_2d(f_2d, train_2d(gd_2d, f_grad=f_2d_grad))"]}],"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"},"kernelspec":{"display_name":"Python 3.7.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"w03_DEMOgd.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}