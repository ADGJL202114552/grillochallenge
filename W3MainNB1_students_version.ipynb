{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjevZgFUgWKi"
      },
      "source": [
        "# Linear regression applied to Option Pricing\n",
        "\n",
        "This code applies linear regression to option pricing under the Blackâ€“Scholes model (BSM) - a widely used differential equation model to price option contracts [[Ref](https://www.investopedia.com/terms/b/blackscholes.asp)].\n",
        "\n",
        "We make use of `BS_Fun.py` for generating data and some other functions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating the data"
      ],
      "metadata": {
        "id": "kSAJa5ZhdS1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "## IMPORTANT: replace with the path to your local drive\n",
        "os.chdir('drive/My Drive/Teaching/LT_2021_2022/ST456/Week03')"
      ],
      "metadata": {
        "id": "fiGYkJJKlSjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DWxcO_qEVOrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCwTn7tSgWKm"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# helper module for generating the dataset\n",
        "from BS_Fun import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBYO8nLXgWKo"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  See lines 8 to 15 on BS_Fun.py for further details.\n",
        "  The bs_call function takes in:\n",
        "    the current price of an asset (S)\n",
        "    the strike price (K)\n",
        "    the maturity (T),\n",
        "    the interest rate (r),\n",
        "    and volatility (sigma)\n",
        "\n",
        "  In the below example, we take S=10, K=15, T=1, r=0, sigma=1\n",
        "'''\n",
        "bs_call(10,*[15,1,0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WUGHYabgWKp"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "In the below example, we take a variety of S, and fix the same K, T, r, sigma as previous.\n",
        "This enables us to further plot the price of the options against various strike price, ceteris paribus.\n",
        "'''\n",
        "s = np.arange(1,40,0.1)\n",
        "trial = BS_Options_Pricing_S(s,[15,1,0,1])\n",
        "trial.make_calls()\n",
        "trial.make_puts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLivsT9BgWKp"
      },
      "outputs": [],
      "source": [
        "data=df({'Stock price':s,\n",
        "    'Calls':trial.calls,\n",
        "    'Puts':trial.puts}\n",
        "       )\n",
        "data.plot('Stock price',figsize=(15,5),legend=True,grid=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IKC5ns-gWKq"
      },
      "source": [
        "## Non-linear approximation\n",
        "\n",
        "### An example of $\\mathbb{R} \\to \\mathbb{R}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3at5VqdGgWKq"
      },
      "outputs": [],
      "source": [
        "def generate_sample_no_noise(S=20,K=np.arange(10,30,0.1),\n",
        "                             T=1,r=0,true_sigma=1):\n",
        "    '''\n",
        "    We receive data over different calls, and would like to predict further on the other strike prices\n",
        "    Suppose we do not have access to sigma, so we use neural networks to make the predictions.\n",
        "    We first assume that we have no noise in our data :)\n",
        "    '''\n",
        "    trial=BS_Options_Pricing_K(K,[S,T,r,true_sigma])\n",
        "    trial.make_calls()\n",
        "    data =df({'Strike price':K, 'Call price':trial.calls})\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D21EuVo9gWKr"
      },
      "outputs": [],
      "source": [
        "#(x_1,y_1),...,(x_n,y_n)\n",
        "data = generate_sample_no_noise()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "CpeyehDWoTSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "fV6bwSW_oisV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar7Y_MdFgWKr"
      },
      "outputs": [],
      "source": [
        "data.plot.scatter('Strike price','Call price')\n",
        "# sns.lmplot(x='Strike price',y='Call price',data=data,fit_reg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSxmpK5DgWKs"
      },
      "source": [
        "## Model definition \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6YlSs9XgWKt"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZajPOxtygWKt"
      },
      "outputs": [],
      "source": [
        "# if you want the results to be reproducible.\n",
        "seed_value=0\n",
        "tf.random.set_seed(seed_value)\n",
        "np.random.seed(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y52hLc9HgWKt"
      },
      "source": [
        "### Data split and normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOd4ppIYgWKu"
      },
      "outputs": [],
      "source": [
        "# splitting into features and label (target)\n",
        "feature = data['Strike price']\n",
        "target  = data['Call price']\n",
        "\n",
        "# feature normalization layer (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization)\n",
        "# shift and scale inputs into a distribution centered around 0 with standard deviation 1.\n",
        "# The mean and variance values for the layer must be either supplied on construction or learned via adapt(). \n",
        "# adapt() will compute the mean and variance of the data and store them as the layer's weights. \n",
        "# adapt() should be called before fit(), evaluate(), or predict().\n",
        "feature_normaliser = layers.Normalization(input_shape=[1,], axis=None, name='normaliser')\n",
        "feature_normaliser.adapt(feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition\n",
        "\n",
        "We will be using a Tensorflow [regression model](https://www.tensorflow.org/tutorials/keras/regression).\n"
      ],
      "metadata": {
        "id": "RSg6k5kUntYz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY2vNEusgWKu"
      },
      "outputs": [],
      "source": [
        "# sequential model\n",
        "linear_regression = keras.Sequential(name='First_model')\n",
        "# feature normalization applied to the input features\n",
        "linear_regression.add(feature_normaliser)\n",
        "# linear model\n",
        "linear_regression.add(layers.Dense(units=1, name='Dense'))\n",
        "\n",
        "# we can get a summary of our model\n",
        "linear_regression.summary()\n",
        "\n",
        "# and compile the model with \"standard\" parameters: SGD, learning rate and loss function\n",
        "linear_regression.compile(\n",
        "    optimizer=tf.optimizers.SGD(learning_rate=0.1),\n",
        "    loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyPoCV3KgWKu"
      },
      "source": [
        "Question to discuss in group [3 mins]: why are there 5 parameters? \n",
        "Write down the model and illustrate these 5 parameters.\n",
        "\n",
        "---\n",
        "\n",
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z16QpQapgWKu"
      },
      "outputs": [],
      "source": [
        "# we use %%time to get some execution time statistics\n",
        "%%time\n",
        "## history is a dictionary capturing training data\n",
        "history = linear_regression.fit(\n",
        "    feature,\n",
        "    target,\n",
        "    epochs=100,\n",
        "    # suppress logging.\n",
        "    verbose=0,\n",
        "    # calculate validation results on 0% of the training data.\n",
        "    validation_split = 0,\n",
        "    validation_data = None)\n",
        "\n",
        "#Reference: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQTN2OM4gWKv"
      },
      "outputs": [],
      "source": [
        "# model's final weights\n",
        "linear_regression.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting targets"
      ],
      "metadata": {
        "id": "_9QkFZZaxXo2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpckGHUggWKw"
      },
      "outputs": [],
      "source": [
        "y_pred = linear_regression.predict(feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwkVknc9gWKw"
      },
      "outputs": [],
      "source": [
        "plt.plot(y_pred, label='ypred')\n",
        "plt.plot(target, label='target')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlabel('Number of samples')\n",
        "plt.ylabel('Call price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Exercise:** evaluate the model using three different methods:\n",
        "\n",
        "\t* `keras.metrics`\n",
        "\t* `model.evaluate`\n",
        "\t* `history.history`"
      ],
      "metadata": {
        "id": "8j1QreZ9qNZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For students practices"
      ],
      "metadata": {
        "id": "14nUGLnuqhDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkMY_3mXgWKx"
      },
      "source": [
        "### Non-linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWuSWGG4gWKx"
      },
      "outputs": [],
      "source": [
        "Model1 = keras.Sequential(name='One_layer_model')\n",
        "Model1.add(feature_normaliser)\n",
        "Model1.add(layers.Dense(1,activation='sigmoid',name='sigmoid'))\n",
        "Model1.add(layers.Dense(1,name='dense_after_sigmoid'))\n",
        "\n",
        "Model1.summary()\n",
        "\n",
        "Model1.compile(\n",
        "    optimizer=tf.optimizers.SGD(learning_rate=0.1),\n",
        "    loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lv1aM5jgWKy"
      },
      "source": [
        "Exercise and Question to discuss in group [5 mins]: Write down the formula and disuss what is expected for the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYf60YyJgWKy"
      },
      "outputs": [],
      "source": [
        "history = Model1.fit(\n",
        "    feature,\n",
        "    target,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_split = 0,\n",
        "    validation_data = None)\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H_laRU3gWKy"
      },
      "outputs": [],
      "source": [
        "Model1.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmyYzUR-gWKy"
      },
      "outputs": [],
      "source": [
        "y_pred=Model1.predict(feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13bsjk09gWKy"
      },
      "outputs": [],
      "source": [
        "plt.plot(y_pred)\n",
        "plt.plot(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6_SSoYYgWKy"
      },
      "outputs": [],
      "source": [
        "y_pred = y_pred.reshape(target.shape)\n",
        "keras.metrics.mean_squared_error(target,y_pred).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2P0lfSOgWKz"
      },
      "outputs": [],
      "source": [
        "Model1.evaluate(feature,target,verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFOtgCxKgWKz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-linear regression (second model)"
      ],
      "metadata": {
        "id": "Mpo9oX4P4Nxk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvHiiiNUgWKz"
      },
      "outputs": [],
      "source": [
        "Model2 = keras.Sequential(name='Two_layers_model')\n",
        "Model2.add(feature_normaliser)\n",
        "Model2.add(layers.Dense(2,activation='sigmoid',name='sigmoid0'))\n",
        "Model2.add(layers.Dense(2,name='linear_2X2'))\n",
        "Model2.add(layers.Dense(4,activation='sigmoid',name='sigmoid1'))\n",
        "Model2.add(layers.Dense(1,name='linear_4X1'))\n",
        "\n",
        "Model2.summary()\n",
        "\n",
        "Model2.compile(\n",
        "    optimizer=tf.optimizers.SGD(learning_rate=0.1),\n",
        "    loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWI_LL44gWKz"
      },
      "outputs": [],
      "source": [
        "history = Model2.fit(\n",
        "    feature,\n",
        "    target,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_split = 0,\n",
        "    validation_data = None)\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxCOX8acgWKz"
      },
      "outputs": [],
      "source": [
        "y_pred=Model2.predict(feature)\n",
        "\n",
        "plt.plot(y_pred)\n",
        "plt.plot(target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model2.evaluate(feature,target,verbose=0)"
      ],
      "metadata": {
        "id": "3ViOf5X_4l-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98QG0sMhgWKz"
      },
      "source": [
        "### Summary of achievements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjC47ANggWK0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(linear_regression.predict(feature), label='Linear Model')\n",
        "plt.plot(Model1.predict(feature), label='Model1')\n",
        "plt.plot(Model2.predict(feature), label='Model2')\n",
        "plt.plot(target, label='Actual_data')\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDq251lPgWK0"
      },
      "source": [
        "## Validation loss\n",
        "\n",
        "We now look at the validation step, more precisely the validation loss.\n",
        "\n",
        "We use the same models from the previous section, training over 100 epochs. The difference is that we make use of the `validation_data` parameter to specify a portion of the dataset to be used for validation purposes (i.e., we don't train the model over this portion)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5AvlYLngWK0"
      },
      "outputs": [],
      "source": [
        "seed_value = 0\n",
        "tf.random.set_seed(seed_value)\n",
        "np.random.seed(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`data_validiation` will be the data samples used for validation, whereas `data_train` is the training sample."
      ],
      "metadata": {
        "id": "OrCKVnFAB0CL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXdpZ6STgWK0"
      },
      "outputs": [],
      "source": [
        "data = generate_sample_no_noise(K=np.arange(1,40,0.01))\n",
        "indices = np.random.randint(low=0, high=data.shape[0], size=int(data.shape[0]*0.3))\n",
        "data_validiation = data.loc[indices]\n",
        "data_train = data.drop(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE7yYA_kgWK0"
      },
      "outputs": [],
      "source": [
        "feature_train = data_train['Strike price']\n",
        "target_train  = data_train['Call price']\n",
        "feature_normaliser = layers.Normalization(input_shape=[1,], axis=None,name='normaliser')\n",
        "feature_normaliser.adapt(feature_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First model using validation data"
      ],
      "metadata": {
        "id": "jwh8MwcPCH-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlRBRDfygWK0"
      },
      "outputs": [],
      "source": [
        "linear_regression = keras.Sequential(name='First_model')\n",
        "linear_regression.add(feature_normaliser)\n",
        "linear_regression.add(layers.Dense(units=1, name='dense'))\n",
        "\n",
        "linear_regression.compile(\n",
        "    optimizer=tf.optimizers.SGD(learning_rate=0.1),\n",
        "    loss='mean_squared_error')\n",
        "\n",
        "history0 = linear_regression.fit(\n",
        "    feature_train,\n",
        "    target_train,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_data = (data_validiation['Strike price'],\n",
        "                      data_validiation['Call price']))\n",
        "\n",
        "plt.plot(history0.history['loss'], label='training loss')\n",
        "plt.plot(history0.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second and third models using validation data"
      ],
      "metadata": {
        "id": "sxm3172CCQIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax2ycLM7gWK1"
      },
      "outputs": [],
      "source": [
        "Model1 = keras.Sequential(name='One_layer_model')\n",
        "Model1.add(feature_normaliser)\n",
        "Model1.add(layers.Dense(1,activation='sigmoid',name='sigmoid'))\n",
        "Model1.add(layers.Dense(1,name='dense_after_sigmoid'))\n",
        "\n",
        "Model1.compile(\n",
        "    optimizer=tf.optimizers.SGD(learning_rate=0.1),\n",
        "    loss='mean_squared_error')\n",
        "\n",
        "Model2 = keras.Sequential(name='Two_layers_model')\n",
        "Model2.add(feature_normaliser)\n",
        "Model2.add(layers.Dense(2,activation='sigmoid',name='sigmoid0'))\n",
        "Model2.add(layers.Dense(2,name='linear_2X2'))\n",
        "Model2.add(layers.Dense(4,activation='sigmoid',name='sigmoid1'))\n",
        "Model2.add(layers.Dense(1,name='linear_4X1'))\n",
        "\n",
        "Model2.compile(\n",
        "    optimizer=tf.optimizers.SGD(learning_rate=0.1),\n",
        "    loss='mean_squared_error')\n",
        "\n",
        "history1 = Model1.fit(\n",
        "    feature_train,\n",
        "    target_train,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_data = (data_validiation['Strike price'],\n",
        "                      data_validiation['Call price']))\n",
        "\n",
        "history2 = Model2.fit(\n",
        "    feature_train,\n",
        "    target_train,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_data = (data_validiation['Strike price'],\n",
        "                      data_validiation['Call price']))\n",
        "plt.figure()\n",
        "plt.plot(history1.history['loss'], label='Model 1 training loss',color='darkviolet')\n",
        "plt.plot(history1.history['val_loss'], label='Model 1 validation loss',color='violet')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history2.history['loss'], label='Model 2 training loss',color='darkgreen')\n",
        "plt.plot(history2.history['val_loss'], label='Model 2 validation loss',color='lime')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing models"
      ],
      "metadata": {
        "id": "CqlWoi8MCqK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZCM2EUSgWK1"
      },
      "outputs": [],
      "source": [
        "plt.plot(history0.history['loss'], label='Linear model training loss')\n",
        "plt.plot(history1.history['loss'], label='Model 1 training loss',color='darkviolet')\n",
        "plt.plot(history2.history['loss'], label='Model 2 training loss',color='darkgreen')\n",
        "plt.ylim([0, 2])\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs5LNX_ygWK1"
      },
      "outputs": [],
      "source": [
        "plt.plot(history0.history['val_loss'], label='Linear model validation loss',color='royalblue')\n",
        "plt.plot(history1.history['val_loss'], label='Model 1 validation loss',color='violet')\n",
        "plt.plot(history2.history['val_loss'], label='Model 2 validation loss',color='lime')\n",
        "plt.ylim([0,2])\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09xLK6s7gWK1"
      },
      "outputs": [],
      "source": [
        "data_validiation.sort_index(ascending=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PshkNYYtgWK1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(linear_regression.predict(data_validiation['Strike price']),label='Linear Model')\n",
        "plt.plot(Model1.predict(data_validiation['Strike price']),label='Model1')\n",
        "plt.plot(Model2.predict(data_validiation['Strike price']),label='Model2')\n",
        "plt.plot(data_validiation['Call price'].values,label='data')\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMpaPaYOgWK1"
      },
      "source": [
        "## Validation / testing in unseen region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpimpJk5gWK2"
      },
      "outputs": [],
      "source": [
        "data_test = generate_sample_no_noise(K=np.arange(40,50,0.01))\n",
        "#data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** What would happen now to testing data in unseen region?\n",
        "\n",
        "`model.predict(data_test['Strike price'])`"
      ],
      "metadata": {
        "id": "s4i-AQzJuFhm"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "W3MainNB1_students_version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}